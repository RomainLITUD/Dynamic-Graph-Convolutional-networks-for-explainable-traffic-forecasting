{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "from custom_model.layers_keras import *\n",
    "from custom_model.model_keras import *\n",
    "from custom_model.math_utils import *\n",
    "from utils_vis import *\n",
    "from keras import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 2\n",
    "horizon = 20\n",
    "OBS = 30//dt-1\n",
    "PRED = horizon//dt\n",
    "\n",
    "model_name = 'dfn'\n",
    "\n",
    "Data = h5py.File('Datasets/RRot_cc2_20.h5', 'r')\n",
    "x_train = np.array(Data['Speed_obs_train'])\n",
    "y_train = np.array(Data['Speed_pred_train'])\n",
    "e_train = np.array(Data['E_train'])\n",
    "x_test = np.array(Data['Speed_obs_test'])\n",
    "y_test = np.array(Data['Speed_pred_test'])\n",
    "e_test = np.array(Data['E_test'])\n",
    "\n",
    "'''\n",
    "x_test = x_test[:3600]\n",
    "y_test = y_test[:3600]\n",
    "e_test = e_test[:3600]\n",
    "\n",
    "x_test = np.delete(x_test, np.s_[3150:3180], axis=0)\n",
    "y_test = np.delete(y_test, np.s_[3150:3180], axis=0)\n",
    "e_test = np.delete(e_test, np.s_[3150:3180], axis=0)\n",
    "\n",
    "x_test = x_test[:1440]\n",
    "y_test = y_test[:1440]\n",
    "e_test = e_test[:1440]\n",
    "\n",
    "x_test = np.delete(x_test, np.s_[1260:1272], axis=0)\n",
    "y_test = np.delete(y_test, np.s_[1260:1272], axis=0)\n",
    "e_test = np.delete(e_test, np.s_[1260:1272], axis=0)\n",
    "'''\n",
    "x_train = x_train[:,-OBS:]\n",
    "y_train = y_train[:,:PRED]\n",
    "e_train =e_train[:,:PRED]\n",
    "y_test = y_test[:,:PRED]\n",
    "e_test =e_test[:,:PRED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'dfn':\n",
    "    model = create_embed_model(obs_timesteps=OBS, pred_timesteps=PRED, nb_nodes=208, k=3, dgc_mode='dgc',model_name='dfn')\n",
    "elif model_name == 'dgcgru':\n",
    "    model = create_embed_model(obs_timesteps=OBS, pred_timesteps=PRED, nb_nodes=208, k=2, dgc_mode='dgc',model_name='dgcgru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = RNN(RecurrentDGC(k=3, units=64), return_sequences=True, return_state=True)\n",
    "decoder = RNN(RecurrentDGC(k=3, units=64), return_sequences=True, return_state=True)\n",
    "        \n",
    "#readout = Dense(208, activation='sigmoid')\n",
    "unstack_k = Lambda(unstack)\n",
    "choice = Scheduled()\n",
    "    \n",
    "input_obs = Input(shape=(OBS, 208, 1)) \n",
    "input_gt = Input(shape=(PRED, 208, 1)) #(None, 4, 208, 1)\n",
    "encoder_inputs = Lambda(lambda x: K.squeeze(x, axis = -1))(input_obs) # (None, 29, 208)\n",
    "    \n",
    "encoder_outputs, state_h = encoder(encoder_inputs)\n",
    "unstacked = unstack_k(input_gt) #[(None, 208, 1) x 4] list\n",
    "    \n",
    "initial = unstacked[0] #(None, 208, 1)\n",
    "decoder_inputs = Lambda(lambda x: K.permute_dimensions(x, (0,2,1)))(initial) #(None, 1, 208)\n",
    "decoder_outputs_new, state_h_new = decoder(decoder_inputs, initial_state=state_h)\n",
    "state_h = state_h_new\n",
    "#prediction = []\n",
    "feature = []\n",
    "#decoded_results = readout(decoder_outputs_new)\n",
    "#prediction.append(decoded_results)\n",
    "feature.append(decoder_outputs_new)\n",
    "if PRED > 1:       \n",
    "    for i in range(1,PRED):\n",
    "        decoder_inputs = unstacked[i]#(None, 208, 1)\n",
    "        decoder_inputs = Lambda(lambda x: K.permute_dimensions(x, (0,2,1)))(decoder_inputs)#(None, 1, 208)\n",
    "        decoder_outputs_new, state_h_new = decoder(decoder_inputs, initial_state=state_h)\n",
    "        state_h = state_h_new\n",
    "        #decoded_results = readout(decoder_outputs_new)\n",
    "        feature.append(decoder_outputs_new)\n",
    "    \n",
    "outputs = Lambda(stack)(feature)\n",
    "model = Model([input_obs, input_gt], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'load_models/cc_dggru-'+str(dt)+'-'+str(horizon)+'_k2.h5'\n",
    "filename = 'load_models/cl_dgfn_dt2.h5'\n",
    "file=h5py.File(filename,'r')\n",
    "weight = []\n",
    "for i in range(len(file.keys())):\n",
    "    weight.append(file['weight'+str(i)][:])\n",
    "model.set_weights(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict([x_test,e_test])\n",
    "for i in range(1,PRED+1):   \n",
    "    print(MAP(y_test[:,:i]*120, y[:,:i]*120), ' ',100*MAPE(y_test[:,:i]*120, y[:,:i]*120), ' ',RMSE(y_test[:,:i]*120, y[:,:i]*120))\n",
    "print('##########')\n",
    "for i in range(PRED):\n",
    "    print(MAP(y_test[:,i]*120, y[:,i]*120), ' ',100*MAPE(y_test[:,i]*120, y[:,i]*120), ' ',RMSE(y_test[:,i]*120, y[:,i]*120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 2\n",
    "start = 150*(day-1)\n",
    "end = start+150\n",
    "j=3\n",
    "gt = [y_test[i] for i in range(start,end,PRED)]\n",
    "pred = [y[i][:j] for i in range(start,end,j)]\n",
    "\n",
    "ground_truth = np.concatenate(gt, axis=0)\n",
    "prediction = np.concatenate(pred, axis=0)\n",
    "\n",
    "print(ground_truth.shape)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(ground_truth, title1 = 'speed ground-truth on Rot_cc, 15/01/2018 (dt=2min)', title2 = ' ', nb = 199, figtitle='test.PNG', time=150, dt=2/60, color='jet_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(prediction, title1 = '10 min prediction of DGGRU, k=2', title2 = ' ',nb = 208, figtitle='test.PNG',time=150,dt=2/60,color='jet_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = model.predict([x_train,e_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16500, 2, 199, 199)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = y[...,1:]\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16500, 1, 199, 199)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 0\n",
    "W = W[:,[step]]\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [weight.name for layer in model.layers for weight in layer.weights]\n",
    "weights = model.get_weights()\n",
    "\n",
    "for name, weight in zip(names, weights):\n",
    "    print(name, weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B,C = Speed_k_correlation(ground_truth=120*e_train[:,[step]].squeeze(axis=-1), weights=W, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115, 110, 105, 100, 95, 90, 85, 80, 75, 70, 65, 60, 55, 50, 45, 40, 35, 30, 25, 20, 15, 10, 5, 0]\n",
      "[  9498   2869   9708  94848 217268 143263  81729  44314  52046  24567\n",
      "  15370  13523  12021  10980  12402  13771  12879  10873   9139   8303\n",
      "   7366   6909   6013   1216]\n"
     ]
    }
   ],
   "source": [
    "interval = 16500//4\n",
    "start = 3*interval\n",
    "end = start+interval\n",
    "E = 120*e_train[:,[step]].squeeze(axis=-1)\n",
    "A,B,C = Speed_k_correlation(ground_truth=E[start:end], weights=W[start:end], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Compare(ground_truth=120*e_train[:,[step]].squeeze(), weights=W.squeeze(), k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4918829298542389\n",
      "1.618662196086822\n",
      "1.5683352740981844\n",
      "1.498229727372614\n",
      "1.4540897061251448\n",
      "1.4443426447982732\n",
      "1.464586654649521\n",
      "1.4238072498184244\n",
      "1.3228696468129253\n",
      "1.2102664348577694\n",
      "1.1817072201454852\n",
      "1.0276381397483567\n",
      "0.9371024439746466\n",
      "0.8569835691301247\n",
      "0.5648342123512355\n",
      "0.3841574973123835\n",
      "0.5188875680312486\n",
      "-0.05351832058036121\n",
      "-0.006326308362099959\n",
      "0.39109668033037215\n",
      "0.6634431527907145\n",
      "0.3293065530923507\n",
      "0.4060473105460365\n",
      "0.797215134954234\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(A)):\n",
    "    print(A[23-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(C)):\n",
    "    print(np.var(np.array(C[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,5))\n",
    "labels = [i for i in range(0, 125, 5)]\n",
    "y_lab = [-3.5,-2.5,-1.5,-0.5,0.5,1.5,2.5,3.5]\n",
    "plt.xlabel(\"v(km/h)\",fontsize=22)\n",
    "plt.xlim(0,120)\n",
    "plt.ylim(-3.5,3.5)\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.ylabel(\"Spatial importances J()\",fontsize=22)\n",
    "plt.pcolormesh(labels, y_lab, np.flip(B,axis=1), cmap = 'jet')\n",
    "plt.title('Spatial Correlations vs speed on ROTCL, dt=5min', fontsize=20)\n",
    "plt.colorbar()\n",
    "plt.clim(0,0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [sorted(np.array(C[23-i])) for i in range(24)]\n",
    "labels = [i for i in range(5, 125, 5)]\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.xlabel(\"v(km/h)\",fontsize=24)\n",
    "plt.xlim(0,125)\n",
    "plt.ylim(-3,3)\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.ylabel(\"attention coefficient f\",fontsize=24)\n",
    "plt.title(\"Attention coefficent distributions & mean values on ROTCL, dt=5min\",fontsize=24)\n",
    "pc = plt.violinplot(\n",
    "        data, labels, widths=4., showmeans=True, showmedians=False,\n",
    "        showextrema=False, bw_method='silverman')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('Figs/violin2.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = 100*78\n",
    "end = head+101\n",
    "s = 199\n",
    "gt = 120*y_train[:,[step]].squeeze()\n",
    "\n",
    "plt.figure(figsize = (15,8))\n",
    "y_lab = [0.2*i for i in range(s)]\n",
    "x_lab = [14+3/60*i for i in range(101)]\n",
    "#y, x = np.mgrid[slice(0, (s+1)*0.2, 0.2), slice(14-4/60., 14+150*2/60., 2/60)]\n",
    "plt.xlabel(\"time (PM)\",fontsize=22)\n",
    "plt.xlim(14,19)\n",
    "plt.ylim(0,(s-0.2)*0.2)\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.ylabel(\"position (km)\",fontsize=22)\n",
    "plt.pcolormesh(x_lab, y_lab, f[head:end].transpose(), cmap = 'coolwarm')\n",
    "#levels1 = MaxNLocator(nbins=120).tick_values(-3, 3)\n",
    "#plt.contourf(x[:-1, :-1] + 0.2/2.,\n",
    "                  #y[:-1, :-1] + 2/120., [head:end].transpose(), levels=levels1,\n",
    "                  #cmap='RdYlBu_r')\n",
    "plt.title('Attention coefficient evolution on 13-11-2018 (dt=4min, ROT_CC)', fontsize=20)\n",
    "plt.colorbar()\n",
    "#plt.clim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
